{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from multitask_missing_q10 import get_loader, MySet, binary_cross_entropy_with_logits, TemporalDecay, FeatureRegression, to_var\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F   \n",
    "from torch.autograd import Variable\n",
    "from lightning.pytorch import seed_everything\n",
    "seed_everything(42)\n",
    "\n",
    "SEQ_LEN = 40                           # number of period in the ts, t = 1, 2, 3, 4, 5.\n",
    "RNN_HID_SIZE = 32                     # hidden node of the rnn \n",
    "batch_size = 32\n",
    "model_name = 'BRITS_ATT' # RITS\n",
    "question = 'feeling_lately'\n",
    "open_face = 'eye_gaze'\n",
    "epochs = 100\n",
    "#N_SERIES = 12                          # number of series Rd, 12:eye, 136:landmark,14:action unit\n",
    "lr = 1e-3\n",
    "repetitions = 1\n",
    "ratio_missing = 0.05\n",
    "type_missing = 'Random' # CMV\n",
    "rnn_name = 'LSTM' # GRU\n",
    "experiment_name = 'exp01'\n",
    "\n",
    "if open_face=='action_unit':\n",
    "    N_SERIES = 14  # 14, for action unit\n",
    "elif open_face=='eye_gaze':\n",
    "    N_SERIES = 12\n",
    "elif open_face=='landmark':\n",
    "    N_SERIES = 136\n",
    "elif open_face=='all':\n",
    "    N_SERIES = (14+12+136)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_rits_att(nn.Module):\n",
    "    def __init__(self, rnn_name='LSTM'):\n",
    "        super(Model_rits_att, self).__init__()\n",
    "        self.rnn_name = rnn_name\n",
    "        self.build()\n",
    "        \n",
    "        # Attention following AudiBert \n",
    "        self.W_s1 = nn.Linear(RNN_HID_SIZE, 350)\n",
    "        self.W_s2 = nn.Linear(350, 30)\n",
    "    def build(self):\n",
    "        if self.rnn_name=='LSTM':\n",
    "            self.rnn_cell = nn.LSTMCell(N_SERIES * 2, RNN_HID_SIZE)\n",
    "        elif self.rnn_name=='GRU':\n",
    "            self.rnn_cell = nn.GRUCell(N_SERIES * 2, RNN_HID_SIZE)\n",
    "\n",
    "        self.temp_decay_h = TemporalDecay(input_size = N_SERIES, output_size = RNN_HID_SIZE, diag = False)\n",
    "        self.temp_decay_x = TemporalDecay(input_size = N_SERIES, output_size = N_SERIES, diag = True)\n",
    "\n",
    "        self.hist_reg = nn.Linear(RNN_HID_SIZE, N_SERIES)\n",
    "        self.feat_reg = FeatureRegression(N_SERIES)\n",
    "\n",
    "        self.weight_combine = nn.Linear(N_SERIES * 2, N_SERIES)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 0.25)\n",
    "        #self.out = nn.Linear(RNN_HID_SIZE, 1)\n",
    "        self.out = nn.Linear(RNN_HID_SIZE*30, 1)\n",
    "        \n",
    "    def attention_rnn(self, rnn_output):\n",
    "        #attn_weight_matrix = self.W_s2(F.tanh(self.W_s1(lstm_output)))\n",
    "        attn_weight_matrix = self.W_s2(torch.tanh(self.W_s1(rnn_output)))\n",
    "        attn_weight_matrix = attn_weight_matrix.permute(0, 2, 1)\n",
    "        attn_weight_matrix = F.softmax(attn_weight_matrix, dim=2)\n",
    "        return attn_weight_matrix\n",
    "    \n",
    "    def _assemble_input_for_training(self, data): \n",
    "\n",
    "        \"\"\"\n",
    "        Collate function for the BRITS dataloader.\n",
    "\n",
    "        Args:\n",
    "            data (List[Dict]): List of records containing time series data from BRITSDataFormat.\n",
    "\n",
    "        Returns:\n",
    "            Dict: A dictionary containing the collated data.\n",
    "\n",
    "        Raises:\n",
    "            AssertionError: If the required keys are not found in the input list.\n",
    "        \"\"\"\n",
    "        # assuming data is a dict of tensors with keys: 'X', 'missing_mask', 'deltas', 'back_X', 'back_missing_mask', 'back_deltas', 'label'\n",
    "        for k, v in data.items():\n",
    "            if k == 'label':\n",
    "                data[k] = v.long()\n",
    "            else:\n",
    "                data[k] = v.type_as(next(iter(self.W_s1.parameters())))\n",
    "        final_dict = {\n",
    "            'forward': {\"X\": data['X'], \"missing_mask\": data['missing_mask'], \"deltas\": data['deltas']}, #TODO: check if this is correct\n",
    "            'backward': {\"X\": data['back_X'], \"missing_mask\": data['back_missing_mask'], \"deltas\": data['back_deltas']},\n",
    "            'label': data['label']\n",
    "        }\n",
    "        return final_dict \n",
    "    \n",
    "    def forward(self, data, direct, filter_train=False):\n",
    "        is_train = data['is_train'].view(-1, 1)\n",
    "        non_zero = torch.where(is_train == 1)[0] if filter_train else slice(None)\n",
    "\n",
    "        # Original sequence with 24 time steps\n",
    "        values = data[direct]['values'][non_zero]\n",
    "        masks = data[direct]['masks'][non_zero]\n",
    "        deltas = data[direct]['deltas'][non_zero]\n",
    "\n",
    "        # to store historical hidden size from rnn\n",
    "        H_rnn = torch.zeros(values.shape[0], SEQ_LEN, RNN_HID_SIZE)  # (batch, sequence, hiden_dize)\n",
    "\n",
    "        evals = data[direct]['evals']\n",
    "        eval_masks = data[direct]['eval_masks']\n",
    "\n",
    "        labels = data['label'].view(-1, 1)[non_zero]\n",
    "\n",
    "        h = Variable(torch.zeros((values.size()[0], RNN_HID_SIZE)))\n",
    "        c = Variable(torch.zeros((values.size()[0], RNN_HID_SIZE)))\n",
    "\n",
    "        x_loss = 0.0\n",
    "        y_loss = 0.0\n",
    "\n",
    "        imputations = []\n",
    "\n",
    "        for t in range(SEQ_LEN):\n",
    "            x = values[:, t, :] # every sample in batch, t'th time step, all features\n",
    "            m = masks[:, t, :] # every sample in batch, t'th time step, all features\n",
    "            d = deltas[:, t, :] # every sample in batch, t'th time step, all features\n",
    "\n",
    "            gamma_h = self.temp_decay_h(d) # reshaped deltas to rnn_hidden_size\n",
    "            gamma_x = self.temp_decay_x(d) # reshaped deltas to number time steps\n",
    "\n",
    "            h = h * gamma_h\n",
    "\n",
    "            x_h = self.hist_reg(h) # reshapes hidden state to (number of features)\n",
    "            x_loss += torch.sum(torch.abs(x - x_h) * m) / (torch.sum(m) + 1e-5)\n",
    "            # calculates avg absolute error for present predicted values (Based on hidden state) and actual values\n",
    "\n",
    "            x_c =  m * x +  (1 - m) * x_h # this just puts the real values with the predicted values together\n",
    "\n",
    "            z_h = self.feat_reg(x_c) # some? reshaping shape: (bs, n_features), all values\n",
    "            x_loss += torch.sum(torch.abs(x - z_h) * m) / (torch.sum(m) + 1e-5) # some loss of real values and imputed values for the index of real values\n",
    "\n",
    "            alpha = self.weight_combine(torch.cat([gamma_x, m], dim = 1)) # shape: (bs, n_features) all values\n",
    "\n",
    "            c_h = alpha * z_h + (1 - alpha) * x_h\n",
    "            x_loss += torch.sum(torch.abs(x - c_h) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "            c_c = m * x + (1 - m) * c_h\n",
    "\n",
    "            inputs = torch.cat([c_c, m], dim = 1)\n",
    "            if self.rnn_name=='LSTM':\n",
    "                h, c = self.rnn_cell(inputs, (h, c))         # h lstm: torch.Size([1, 32]\n",
    "            elif self.rnn_name=='GRU':\n",
    "                h = self.rnn_cell(inputs, h)                 # h GRU: torch.Size([1, 32]\n",
    "            H_rnn[:,t,:] = h\n",
    "            imputations.append(c_c.unsqueeze(dim = 1))\n",
    "\n",
    "        imputations = torch.cat(imputations, dim = 1)\n",
    "\n",
    "        # Attentions \n",
    "        attn_weight_matrix = self.attention_rnn(H_rnn)\n",
    "        hidden_matrix = torch.bmm(attn_weight_matrix, H_rnn)\n",
    "        attention_output = hidden_matrix.view(-1, hidden_matrix.size()[1]*hidden_matrix.size()[2])\n",
    "\n",
    "        y_h = self.out(attention_output)\n",
    "        y_loss = binary_cross_entropy_with_logits(y_h, labels, reduce = False)\n",
    "        y_loss = torch.sum(y_loss * is_train[non_zero]) / (torch.sum(is_train[non_zero]) + 1e-5)\n",
    "\n",
    "        y_h = torch.sigmoid(y_h)\n",
    "\n",
    "        return {'loss_imp': x_loss / SEQ_LEN, 'loss_clf': y_loss * 0.1, \"loss\": x_loss/SEQ_LEN + y_loss*0.1,  \n",
    "                'predictions': y_h,\n",
    "                'imputations': imputations, \n",
    "                'label': labels, 'is_train': is_train,\n",
    "                'evals': evals, 'eval_masks': eval_masks}\n",
    "\n",
    "    def run_on_batch(self, data, optimizer):\n",
    "        ret = self(data, direct = 'forward')\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            ret['loss'].backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_brits_att(nn.Module):\n",
    "    def __init__(self, rnn_name='LSTM'):\n",
    "        super(Model_brits_att, self).__init__()\n",
    "        self.rnn_name = rnn_name\n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        self.rits_f = Model_rits_att(self.rnn_name)\n",
    "        self.rits_b = Model_rits_att(self.rnn_name)\n",
    "\n",
    "    def forward(self, data):\n",
    "        ret_f = self.rits_f(data, 'forward', filter_train=False)\n",
    "        ret_b = self.reverse(self.rits_b(data, 'backward', filter_train=False))\n",
    "        ret = self.merge_ret(ret_f, ret_b) #TODO finish making \"2\" so you can check if yloss is same for full vs nonzero, and if x_loss is same, gradient update same/different\n",
    "        return ret\n",
    "    \n",
    "    def forward2(self, data):\n",
    "        ret_f = self.rits_f.forward(data, 'forward', filter_train=True)\n",
    "        ret_b = self.reverse(self.rits_b.forward(data, 'backward', filter_train=True))\n",
    "        ret = self.merge_ret(ret_f, ret_b)\n",
    "        return ret\n",
    "\n",
    "\n",
    "    def merge_ret(self, ret_f, ret_b):\n",
    "        loss_f = ret_f['loss']\n",
    "        loss_b = ret_b['loss']\n",
    "        loss_c = self.get_consistency_loss(ret_f['imputations'], ret_b['imputations'])\n",
    "\n",
    "        loss = loss_f + loss_b + loss_c\n",
    "\n",
    "        predictions = (ret_f['predictions'] + ret_b['predictions']) / 2\n",
    "        imputations = (ret_f['imputations'] + ret_b['imputations']) / 2\n",
    "\n",
    "        ret_f['loss'] = loss\n",
    "        ret_f['predictions'] = predictions\n",
    "        ret_f['imputations'] = imputations\n",
    "\n",
    "        return ret_f\n",
    "\n",
    "    def get_consistency_loss(self, pred_f, pred_b):\n",
    "        loss = torch.pow(pred_f - pred_b, 2.0).mean()\n",
    "        return loss\n",
    "\n",
    "    def reverse(self, ret):\n",
    "        def reverse_tensor(tensor_):\n",
    "            if tensor_.dim() <= 1:\n",
    "                return tensor_\n",
    "            indices = range(tensor_.size()[1])[::-1]\n",
    "            indices = Variable(torch.LongTensor(indices), requires_grad = False)\n",
    "\n",
    "            #if torch.cuda.is_available():\n",
    "            #    indices = indices.cuda()\n",
    "\n",
    "            return tensor_.index_select(1, indices)\n",
    "\n",
    "        for key in ret:\n",
    "            ret[key] = reverse_tensor(ret[key])\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def test_run_on_batch(self, data, optimizer):\n",
    "        ret1 = self.forward(data)\n",
    "        ret2 = self.forward2(data)\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            ret1['loss_imp'].backward(retain_graph=True)\n",
    "            gradients_loss1_imp = [param.grad.clone() for name, param in self.named_parameters() if param.grad is not None]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            ret1['loss_clf'].backward(retain_graph=True)\n",
    "            gradients_loss1_clf = [param.grad.clone() for name, param in self.named_parameters() if param.grad is not None]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ret2['loss_imp'].backward(retain_graph=True)\n",
    "            gradients_loss2_imp = [param.grad.clone() for name, param in self.named_parameters() if param.grad is not None]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ret2['loss_clf'].backward(retain_graph=True)\n",
    "            gradients_loss2_clf = [param.grad.clone() for name, param in self.named_parameters() if param.grad is not None]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ret1['loss'].backward(retain_graph=True)\n",
    "            gradients_loss_full1 = [param.grad.clone() for name, param in self.named_parameters() if param.grad is not None]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ret2['loss'].backward(retain_graph=True)\n",
    "            gradients_loss_full2 = [param.grad.clone() for name, param in self.named_parameters() if param.grad is not None]\n",
    "\n",
    "\n",
    "            # check if gradients for imp_loss on ret1 and ret2 are the same\n",
    "            # import pdb; pdb.set_trace()\n",
    "            from itertools import zip_longest\n",
    "            print(f\"Are is_train=0 present in batch?: {torch.any(data['is_train'] == 0)}\")\n",
    "            # loop through zipeed gradients_loss1_imp and gradients_loss2_imp, along with zipped gradients_loss1_clf and gradients_loss2_clf\n",
    "            for i, ((grad1_imp, grad2_imp), (grad1_clf, grad2_clf), (gradfull1, gradfull2)) in enumerate(zip_longest(zip(gradients_loss1_imp, gradients_loss2_imp), zip(gradients_loss1_clf, gradients_loss2_clf), zip(gradients_loss_full1, gradients_loss_full2))):\n",
    "                layer = list(self.named_parameters())[i][0]\n",
    "                print(f\"Are all grads equal for layer {layer} with respect to imp_loss?: {torch.allclose(grad1_imp, grad2_imp, 1e-2)}\")\n",
    "                print(f\"Are all grads equal for layer {layer} with respect to for clf_loss?: {torch.allclose(grad1_clf, grad2_clf, 1e-2)}\")\n",
    "                print(f\"Are all grads equal for layer {layer} with respect to full_loss?: {torch.allclose(gradfull1, gradfull2, 1e-2)}\")\n",
    "                print()\n",
    "            \n",
    "\n",
    "        return ret1, ret2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ricardo_loader = get_loader(\n",
    "    question=question,\n",
    "    open_face=open_face,\n",
    "    ratio_missing=ratio_missing,\n",
    "    type_missing=type_missing,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "model = Model_brits_att(rnn_name=rnn_name)\n",
    "opt = torch.optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khickey/test_impute/env/lib/python3.12/site-packages/torch/cuda/__init__.py:628: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(ricardo_loader))\n",
    "batch = to_var(batch)\n",
    "ret1 = model.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_imp': tensor(1.3762, grad_fn=<DivBackward0>),\n",
       " 'loss_clf': tensor(0.0705, grad_fn=<MulBackward0>),\n",
       " 'loss': tensor(3.0466, grad_fn=<AddBackward0>),\n",
       " 'predictions': tensor([[0.4796],\n",
       "         [0.4785],\n",
       "         [0.4774],\n",
       "         [0.4796],\n",
       "         [0.4771],\n",
       "         [0.4818],\n",
       "         [0.4781],\n",
       "         [0.4764],\n",
       "         [0.4799],\n",
       "         [0.4807],\n",
       "         [0.4815],\n",
       "         [0.4770],\n",
       "         [0.4781],\n",
       "         [0.4785],\n",
       "         [0.4816],\n",
       "         [0.4814],\n",
       "         [0.4775],\n",
       "         [0.4790],\n",
       "         [0.4825],\n",
       "         [0.4771],\n",
       "         [0.4792],\n",
       "         [0.4785],\n",
       "         [0.4781],\n",
       "         [0.4778],\n",
       "         [0.4786],\n",
       "         [0.4751],\n",
       "         [0.4813],\n",
       "         [0.4808],\n",
       "         [0.4763],\n",
       "         [0.4781],\n",
       "         [0.4808],\n",
       "         [0.4784]], grad_fn=<DivBackward0>),\n",
       " 'imputations': tensor([[[ 0.0274,  0.2098, -0.9674,  ..., -0.1025,  0.2313, -0.9459],\n",
       "          [ 0.0100,  0.2078, -0.9595,  ..., -0.0484,  0.2020, -0.9595],\n",
       "          [ 0.1600,  0.2573, -0.9499,  ..., -0.3722,  0.4083, -0.8149],\n",
       "          ...,\n",
       "          [ 0.0385, -0.0483, -0.0135,  ...,  0.0392,  0.0822, -0.0963],\n",
       "          [ 0.0418, -0.0525, -0.0162,  ...,  0.0369,  0.0830, -0.0941],\n",
       "          [ 0.0466, -0.0609, -0.0252,  ...,  0.0364,  0.0835, -0.0901]],\n",
       " \n",
       "         [[ 0.0230,  0.2504, -0.9678,  ..., -0.1237, -0.0829, -0.9088],\n",
       "          [ 0.0424,  0.2503, -0.9662,  ..., -0.1164,  0.4028, -0.9069],\n",
       "          [ 0.0594,  0.2558, -0.9629,  ..., -0.1623,  0.3587, -0.9182],\n",
       "          ...,\n",
       "          [ 0.0364, -0.0477, -0.0175,  ...,  0.0417,  0.0839, -0.0963],\n",
       "          [ 0.0401, -0.0520, -0.0206,  ...,  0.0397,  0.0842, -0.0944],\n",
       "          [ 0.0466, -0.0609, -0.0252,  ...,  0.0364,  0.0835,  0.0354]],\n",
       " \n",
       "         [[ 0.0064,  0.2969, -0.9544,  ..., -0.2587,  0.3658, -0.8937],\n",
       "          [-0.0265,  0.2859, -0.9572,  ..., -0.2414,  0.3761, -0.8942],\n",
       "          [-0.0693,  0.3263, -0.9425,  ..., -0.1997,  0.4308, -0.8796],\n",
       "          ...,\n",
       "          [ 0.0417, -0.1215, -0.9590,  ..., -0.3445,  0.5893, -0.7280],\n",
       "          [ 0.1096,  0.3124, -0.9422,  ..., -0.2712,  0.5721, -0.7651],\n",
       "          [-0.0284,  0.2860, -0.9544,  ..., -0.0700,  0.4321, -0.8963]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.1273,  0.2128, -0.9677,  ..., -0.2746,  0.2959, -0.9134],\n",
       "          [-0.1230,  0.1661, -0.9775,  ..., -0.2815,  0.2657, -0.9210],\n",
       "          [-0.0873, -0.1081, -0.9659,  ..., -0.2843,  0.2590, -0.9223],\n",
       "          ...,\n",
       "          [-0.1071,  0.1583, -0.9804,  ..., -0.2537,  0.3533, -0.8982],\n",
       "          [-0.1574,  0.1780, -0.9693,  ..., -0.1986,  0.2052, -0.9556],\n",
       "          [-0.1969,  0.1431, -0.9658,  ...,  0.0461,  0.3151, -0.9328]],\n",
       " \n",
       "         [[-0.1693,  0.1129, -0.9790,  ..., -0.2565, -0.0273, -0.9660],\n",
       "          [-0.1723,  0.0853, -0.9799,  ..., -0.2597, -0.0645, -0.9619],\n",
       "          [-0.1580,  0.1205, -0.9767,  ..., -0.1845,  0.0064, -0.9686],\n",
       "          ...,\n",
       "          [ 0.0375, -0.0478, -0.0172,  ...,  0.0419,  0.0847, -0.0974],\n",
       "          [ 0.0401, -0.0520, -0.0206,  ...,  0.0397,  0.0842, -0.0944],\n",
       "          [ 0.0466, -0.0609, -0.0252,  ...,  0.0920,  0.0835, -0.0901]],\n",
       " \n",
       "         [[ 0.0685,  0.4059, -0.9105,  ..., -0.1672,  0.0219, -0.9029],\n",
       "          [ 0.0563,  0.3877, -0.9193,  ..., -0.1705,  0.4350, -0.8826],\n",
       "          [ 0.0069,  0.3704, -0.9267,  ..., -0.1166,  0.4695, -0.8714],\n",
       "          ...,\n",
       "          [ 0.0172,  0.3270, -0.9418,  ..., -0.2174,  0.5249, -0.8211],\n",
       "          [ 0.0044,  0.3168, -0.9461,  ..., -0.2169,  0.5158, -0.8256],\n",
       "          [ 0.0034,  0.3078, -0.9492,  ..., -0.1923,  0.5105, -0.8358]]],\n",
       "        grad_fn=<DivBackward0>),\n",
       " 'label': tensor([[1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.]]),\n",
       " 'is_train': tensor([[1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " 'evals': tensor([[[ 0.0274,  0.2098, -0.9674,  ..., -0.1025,  0.2313, -0.9459],\n",
       "          [ 0.0100,  0.2078, -0.9595,  ..., -0.0484,  0.2020, -0.9595],\n",
       "          [ 0.1600,  0.2573, -0.9499,  ..., -0.3722,  0.4083, -0.8149],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0230,  0.2504, -0.9678,  ..., -0.1237,  0.3985, -0.9088],\n",
       "          [ 0.0424,  0.2503, -0.9662,  ..., -0.1164,  0.4028, -0.9069],\n",
       "          [ 0.0594,  0.2558, -0.9629,  ..., -0.1623,  0.3587, -0.9182],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0064,  0.2969, -0.9544,  ..., -0.2587,  0.3658, -0.8937],\n",
       "          [-0.0265,  0.2859, -0.9572,  ..., -0.2414,  0.3761, -0.8942],\n",
       "          [-0.0693,  0.3263, -0.9425,  ..., -0.1997,  0.4308, -0.8796],\n",
       "          ...,\n",
       "          [ 0.0417,  0.2614, -0.9590,  ..., -0.3445,  0.5893, -0.7280],\n",
       "          [ 0.1096,  0.3124, -0.9422,  ..., -0.2712,  0.5721, -0.7651],\n",
       "          [-0.0284,  0.2860, -0.9544,  ..., -0.0700,  0.4321, -0.8963]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.1273,  0.2128, -0.9677,  ..., -0.2746,  0.2959, -0.9134],\n",
       "          [-0.1230,  0.1661, -0.9775,  ..., -0.2815,  0.2657, -0.9210],\n",
       "          [-0.0873,  0.2374, -0.9659,  ..., -0.2843,  0.2590, -0.9223],\n",
       "          ...,\n",
       "          [-0.1071,  0.1583, -0.9804,  ..., -0.2537,  0.3533, -0.8982],\n",
       "          [-0.1574,  0.1780, -0.9693,  ..., -0.1986,  0.2052, -0.9556],\n",
       "          [-0.1969,  0.1431, -0.9658,  ...,  0.0461,  0.3151, -0.9328]],\n",
       " \n",
       "         [[-0.1693,  0.1129, -0.9790,  ..., -0.2565, -0.0304, -0.9660],\n",
       "          [-0.1723,  0.0853, -0.9799,  ..., -0.2597, -0.0645, -0.9619],\n",
       "          [-0.1580,  0.1205, -0.9767,  ..., -0.1845,  0.0064, -0.9686],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.0685,  0.4059, -0.9105,  ..., -0.1672,  0.3944, -0.9029],\n",
       "          [ 0.0563,  0.3877, -0.9193,  ..., -0.1705,  0.4350, -0.8826],\n",
       "          [ 0.0069,  0.3704, -0.9267,  ..., -0.1166,  0.4695, -0.8714],\n",
       "          ...,\n",
       "          [ 0.0172,  0.3270, -0.9418,  ..., -0.2174,  0.5249, -0.8211],\n",
       "          [ 0.0044,  0.3168, -0.9461,  ..., -0.2169,  0.5158, -0.8256],\n",
       "          [ 0.0034,  0.3078, -0.9492,  ..., -0.1923,  0.5105, -0.8358]]]),\n",
       " 'eval_masks': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 1.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 1., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.methods.brits.lightningmodule import BRITSLightningModule\n",
    "\n",
    "model2 = BRITSLightningModule(\n",
    "    rnn_hidden_size=RNN_HID_SIZE,\n",
    "    question=question,\n",
    "    open_face=open_face,\n",
    "    ratio_missing=ratio_missing,\n",
    "    type_missing=type_missing,\n",
    "    rnn_name=rnn_name,\n",
    "    lr=lr,\n",
    "    batch_size=batch_size,\n",
    "    repetitions=repetitions,\n",
    "    epochs=epochs,\n",
    "    experiment_name=experiment_name,\n",
    "    pypots=False\n",
    ")\n",
    "\n",
    "class DummyDataModule:\n",
    "    def __init__(self):\n",
    "        self.data_info = {}\n",
    "class DummyTrainer:\n",
    "    def __init__(self):\n",
    "        self.datamodule = DummyDataModule()\n",
    "\n",
    "model2.trainer = DummyTrainer()\n",
    "model2.trainer.datamodule.data_info = {\n",
    "            'landmark': 136,\n",
    "            'eye_gaze': 12,\n",
    "            'action_unit': 14,\n",
    "            'all': 162,\n",
    "            'n_time_steps': SEQ_LEN,\n",
    "            'n_features': N_SERIES,\n",
    "            'n_classes': 2,\n",
    "        }\n",
    "model2.setup(stage='fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'forward': {'values': tensor([[[ 0.0274,  0.2098, -0.9674,  ..., -0.1025,  0.2313, -0.9459],\n",
       "           [ 0.0100,  0.2078, -0.9595,  ..., -0.0484,  0.2020, -0.9595],\n",
       "           [ 0.1600,  0.2573, -0.9499,  ..., -0.3722,  0.4083, -0.8149],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "          [[ 0.0230,  0.2504, -0.9678,  ..., -0.1237,  0.0000, -0.9088],\n",
       "           [ 0.0424,  0.2503, -0.9662,  ..., -0.1164,  0.4028, -0.9069],\n",
       "           [ 0.0594,  0.2558, -0.9629,  ..., -0.1623,  0.3587, -0.9182],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "          [[ 0.0064,  0.2969, -0.9544,  ..., -0.2587,  0.3658, -0.8937],\n",
       "           [-0.0265,  0.2859, -0.9572,  ..., -0.2414,  0.3761, -0.8942],\n",
       "           [-0.0693,  0.3263, -0.9425,  ..., -0.1997,  0.4308, -0.8796],\n",
       "           ...,\n",
       "           [ 0.0417,  0.0000, -0.9590,  ..., -0.3445,  0.5893, -0.7280],\n",
       "           [ 0.1096,  0.3124, -0.9422,  ..., -0.2712,  0.5721, -0.7651],\n",
       "           [-0.0284,  0.2860, -0.9544,  ..., -0.0700,  0.4321, -0.8963]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.1273,  0.2128, -0.9677,  ..., -0.2746,  0.2959, -0.9134],\n",
       "           [-0.1230,  0.1661, -0.9775,  ..., -0.2815,  0.2657, -0.9210],\n",
       "           [-0.0873,  0.0000, -0.9659,  ..., -0.2843,  0.2590, -0.9223],\n",
       "           ...,\n",
       "           [-0.1071,  0.1583, -0.9804,  ..., -0.2537,  0.3533, -0.8982],\n",
       "           [-0.1574,  0.1780, -0.9693,  ..., -0.1986,  0.2052, -0.9556],\n",
       "           [-0.1969,  0.1431, -0.9658,  ...,  0.0461,  0.3151, -0.9328]],\n",
       "  \n",
       "          [[-0.1693,  0.1129, -0.9790,  ..., -0.2565,  0.0000, -0.9660],\n",
       "           [-0.1723,  0.0853, -0.9799,  ..., -0.2597, -0.0645, -0.9619],\n",
       "           [-0.1580,  0.1205, -0.9767,  ..., -0.1845,  0.0064, -0.9686],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "          [[ 0.0685,  0.4059, -0.9105,  ..., -0.1672,  0.0000, -0.9029],\n",
       "           [ 0.0563,  0.3877, -0.9193,  ..., -0.1705,  0.4350, -0.8826],\n",
       "           [ 0.0069,  0.3704, -0.9267,  ..., -0.1166,  0.4695, -0.8714],\n",
       "           ...,\n",
       "           [ 0.0172,  0.3270, -0.9418,  ..., -0.2174,  0.5249, -0.8211],\n",
       "           [ 0.0044,  0.3168, -0.9461,  ..., -0.2169,  0.5158, -0.8256],\n",
       "           [ 0.0034,  0.3078, -0.9492,  ..., -0.1923,  0.5105, -0.8358]]]),\n",
       "  'masks': tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 0., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 0.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 0., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 0., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 0., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 0., 1., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 0., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]]]),\n",
       "  'deltas': tensor([[[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [13., 14., 14.,  ..., 15., 13., 14.],\n",
       "           [14., 15., 15.,  ..., 16., 14., 15.],\n",
       "           [15., 16., 16.,  ..., 17., 15., 16.]],\n",
       "  \n",
       "          [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 4.,  4.,  4.,  ...,  3.,  3.,  3.],\n",
       "           [ 5.,  5.,  5.,  ...,  4.,  4.,  4.],\n",
       "           [ 6.,  6.,  6.,  ...,  5.,  5.,  5.]],\n",
       "  \n",
       "          [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
       "           [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
       "           [ 2.,  2.,  2.,  ...,  2.,  2.,  2.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  1.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
       "           [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
       "           [ 2.,  2.,  2.,  ...,  2.,  2.,  2.]],\n",
       "  \n",
       "          [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [14., 15., 12.,  ..., 14., 13., 14.],\n",
       "           [15., 16., 13.,  ..., 15., 14., 15.],\n",
       "           [16., 17., 14.,  ..., 16., 15., 16.]],\n",
       "  \n",
       "          [[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "           ...,\n",
       "           [ 2.,  2.,  2.,  ...,  2.,  1.,  2.],\n",
       "           [ 2.,  2.,  2.,  ...,  2.,  1.,  2.],\n",
       "           [ 2.,  2.,  2.,  ...,  2.,  1.,  2.]]]),\n",
       "  'evals': tensor([[[ 0.0274,  0.2098, -0.9674,  ..., -0.1025,  0.2313, -0.9459],\n",
       "           [ 0.0100,  0.2078, -0.9595,  ..., -0.0484,  0.2020, -0.9595],\n",
       "           [ 0.1600,  0.2573, -0.9499,  ..., -0.3722,  0.4083, -0.8149],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "          [[ 0.0230,  0.2504, -0.9678,  ..., -0.1237,  0.3985, -0.9088],\n",
       "           [ 0.0424,  0.2503, -0.9662,  ..., -0.1164,  0.4028, -0.9069],\n",
       "           [ 0.0594,  0.2558, -0.9629,  ..., -0.1623,  0.3587, -0.9182],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "          [[ 0.0064,  0.2969, -0.9544,  ..., -0.2587,  0.3658, -0.8937],\n",
       "           [-0.0265,  0.2859, -0.9572,  ..., -0.2414,  0.3761, -0.8942],\n",
       "           [-0.0693,  0.3263, -0.9425,  ..., -0.1997,  0.4308, -0.8796],\n",
       "           ...,\n",
       "           [ 0.0417,  0.2614, -0.9590,  ..., -0.3445,  0.5893, -0.7280],\n",
       "           [ 0.1096,  0.3124, -0.9422,  ..., -0.2712,  0.5721, -0.7651],\n",
       "           [-0.0284,  0.2860, -0.9544,  ..., -0.0700,  0.4321, -0.8963]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.1273,  0.2128, -0.9677,  ..., -0.2746,  0.2959, -0.9134],\n",
       "           [-0.1230,  0.1661, -0.9775,  ..., -0.2815,  0.2657, -0.9210],\n",
       "           [-0.0873,  0.2374, -0.9659,  ..., -0.2843,  0.2590, -0.9223],\n",
       "           ...,\n",
       "           [-0.1071,  0.1583, -0.9804,  ..., -0.2537,  0.3533, -0.8982],\n",
       "           [-0.1574,  0.1780, -0.9693,  ..., -0.1986,  0.2052, -0.9556],\n",
       "           [-0.1969,  0.1431, -0.9658,  ...,  0.0461,  0.3151, -0.9328]],\n",
       "  \n",
       "          [[-0.1693,  0.1129, -0.9790,  ..., -0.2565, -0.0304, -0.9660],\n",
       "           [-0.1723,  0.0853, -0.9799,  ..., -0.2597, -0.0645, -0.9619],\n",
       "           [-0.1580,  0.1205, -0.9767,  ..., -0.1845,  0.0064, -0.9686],\n",
       "           ...,\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "          [[ 0.0685,  0.4059, -0.9105,  ..., -0.1672,  0.3944, -0.9029],\n",
       "           [ 0.0563,  0.3877, -0.9193,  ..., -0.1705,  0.4350, -0.8826],\n",
       "           [ 0.0069,  0.3704, -0.9267,  ..., -0.1166,  0.4695, -0.8714],\n",
       "           ...,\n",
       "           [ 0.0172,  0.3270, -0.9418,  ..., -0.2174,  0.5249, -0.8211],\n",
       "           [ 0.0044,  0.3168, -0.9461,  ..., -0.2169,  0.5158, -0.8256],\n",
       "           [ 0.0034,  0.3078, -0.9492,  ..., -0.1923,  0.5105, -0.8358]]]),\n",
       "  'eval_masks': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 1.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 1., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]])},\n",
       " 'backward': {'values': tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           ...,\n",
       "           [ 0.1600,  0.2573, -0.9499,  ..., -0.3722,  0.4083, -0.8149],\n",
       "           [ 0.0100,  0.2078, -0.9595,  ..., -0.0484,  0.2020, -0.9595],\n",
       "           [ 0.0274,  0.2098, -0.9674,  ..., -0.1025,  0.2313, -0.9459]],\n",
       "  \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           ...,\n",
       "           [ 0.0594,  0.2558, -0.9629,  ..., -0.1623,  0.3587, -0.9182],\n",
       "           [ 0.0424,  0.2503, -0.9662,  ..., -0.1164,  0.4028, -0.9069],\n",
       "           [ 0.0230,  0.2504, -0.9678,  ..., -0.1237,  0.0000, -0.9088]],\n",
       "  \n",
       "          [[-0.0284,  0.2860, -0.9544,  ..., -0.0700,  0.4321, -0.8963],\n",
       "           [ 0.1096,  0.3124, -0.9422,  ..., -0.2712,  0.5721, -0.7651],\n",
       "           [ 0.0417,  0.0000, -0.9590,  ..., -0.3445,  0.5893, -0.7280],\n",
       "           ...,\n",
       "           [-0.0693,  0.3263, -0.9425,  ..., -0.1997,  0.4308, -0.8796],\n",
       "           [-0.0265,  0.2859, -0.9572,  ..., -0.2414,  0.3761, -0.8942],\n",
       "           [ 0.0064,  0.2969, -0.9544,  ..., -0.2587,  0.3658, -0.8937]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.1969,  0.1431, -0.9658,  ...,  0.0461,  0.3151, -0.9328],\n",
       "           [-0.1574,  0.1780, -0.9693,  ..., -0.1986,  0.2052, -0.9556],\n",
       "           [-0.1071,  0.1583, -0.9804,  ..., -0.2537,  0.3533, -0.8982],\n",
       "           ...,\n",
       "           [-0.0873,  0.0000, -0.9659,  ..., -0.2843,  0.2590, -0.9223],\n",
       "           [-0.1230,  0.1661, -0.9775,  ..., -0.2815,  0.2657, -0.9210],\n",
       "           [-0.1273,  0.2128, -0.9677,  ..., -0.2746,  0.2959, -0.9134]],\n",
       "  \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           ...,\n",
       "           [-0.1580,  0.1205, -0.9767,  ..., -0.1845,  0.0064, -0.9686],\n",
       "           [-0.1723,  0.0853, -0.9799,  ..., -0.2597, -0.0645, -0.9619],\n",
       "           [-0.1693,  0.1129, -0.9790,  ..., -0.2565,  0.0000, -0.9660]],\n",
       "  \n",
       "          [[ 0.0034,  0.3078, -0.9492,  ..., -0.1923,  0.5105, -0.8358],\n",
       "           [ 0.0044,  0.3168, -0.9461,  ..., -0.2169,  0.5158, -0.8256],\n",
       "           [ 0.0172,  0.3270, -0.9418,  ..., -0.2174,  0.5249, -0.8211],\n",
       "           ...,\n",
       "           [ 0.0069,  0.3704, -0.9267,  ..., -0.1166,  0.4695, -0.8714],\n",
       "           [ 0.0563,  0.3877, -0.9193,  ..., -0.1705,  0.4350, -0.8826],\n",
       "           [ 0.0685,  0.4059, -0.9105,  ..., -0.1672,  0.0000, -0.9029]]]),\n",
       "  'masks': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 0., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 0., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 0., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 0., 1.]],\n",
       "  \n",
       "          [[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           ...,\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "           [1., 1., 1.,  ..., 1., 0., 1.]]]),\n",
       "  'deltas': tensor([[[ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           [ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           [ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           ...,\n",
       "           [-13., -14., -14.,  ..., -15., -13., -14.],\n",
       "           [-14., -15., -15.,  ..., -16., -14., -15.],\n",
       "           [-15., -16., -16.,  ..., -17., -15., -16.]],\n",
       "  \n",
       "          [[ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           [ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           [ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           ...,\n",
       "           [ -4.,  -4.,  -4.,  ...,  -3.,  -3.,  -3.],\n",
       "           [ -5.,  -5.,  -5.,  ...,  -4.,  -4.,  -4.],\n",
       "           [ -6.,  -6.,  -6.,  ...,  -5.,  -5.,  -5.]],\n",
       "  \n",
       "          [[ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           [ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           [ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           ...,\n",
       "           [ -2.,  -2.,  -2.,  ...,  -2.,  -2.,  -2.],\n",
       "           [ -2.,  -2.,  -2.,  ...,  -2.,  -2.,  -2.],\n",
       "           [ -2.,  -2.,  -2.,  ...,  -2.,  -2.,  -2.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           [ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           [ -0.,  -1.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           ...,\n",
       "           [ -2.,  -2.,  -2.,  ...,  -2.,  -2.,  -2.],\n",
       "           [ -2.,  -2.,  -2.,  ...,  -2.,  -2.,  -2.],\n",
       "           [ -2.,  -2.,  -2.,  ...,  -2.,  -2.,  -2.]],\n",
       "  \n",
       "          [[ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           [ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           [ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           ...,\n",
       "           [-14., -15., -12.,  ..., -14., -13., -14.],\n",
       "           [-15., -16., -13.,  ..., -15., -14., -15.],\n",
       "           [-16., -17., -14.,  ..., -16., -15., -16.]],\n",
       "  \n",
       "          [[ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           [ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           [ -0.,  -0.,  -0.,  ...,  -0.,  -0.,  -0.],\n",
       "           ...,\n",
       "           [ -2.,  -2.,  -2.,  ...,  -2.,  -1.,  -2.],\n",
       "           [ -2.,  -2.,  -2.,  ...,  -2.,  -1.,  -2.],\n",
       "           [ -2.,  -2.,  -2.,  ...,  -2.,  -1.,  -2.]]]),\n",
       "  'evals': tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           ...,\n",
       "           [ 0.1600,  0.2573, -0.9499,  ..., -0.3722,  0.4083, -0.8149],\n",
       "           [ 0.0100,  0.2078, -0.9595,  ..., -0.0484,  0.2020, -0.9595],\n",
       "           [ 0.0274,  0.2098, -0.9674,  ..., -0.1025,  0.2313, -0.9459]],\n",
       "  \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           ...,\n",
       "           [ 0.0594,  0.2558, -0.9629,  ..., -0.1623,  0.3587, -0.9182],\n",
       "           [ 0.0424,  0.2503, -0.9662,  ..., -0.1164,  0.4028, -0.9069],\n",
       "           [ 0.0230,  0.2504, -0.9678,  ..., -0.1237,  0.3985, -0.9088]],\n",
       "  \n",
       "          [[-0.0284,  0.2860, -0.9544,  ..., -0.0700,  0.4321, -0.8963],\n",
       "           [ 0.1096,  0.3124, -0.9422,  ..., -0.2712,  0.5721, -0.7651],\n",
       "           [ 0.0417,  0.2614, -0.9590,  ..., -0.3445,  0.5893, -0.7280],\n",
       "           ...,\n",
       "           [-0.0693,  0.3263, -0.9425,  ..., -0.1997,  0.4308, -0.8796],\n",
       "           [-0.0265,  0.2859, -0.9572,  ..., -0.2414,  0.3761, -0.8942],\n",
       "           [ 0.0064,  0.2969, -0.9544,  ..., -0.2587,  0.3658, -0.8937]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-0.1969,  0.1431, -0.9658,  ...,  0.0461,  0.3151, -0.9328],\n",
       "           [-0.1574,  0.1780, -0.9693,  ..., -0.1986,  0.2052, -0.9556],\n",
       "           [-0.1071,  0.1583, -0.9804,  ..., -0.2537,  0.3533, -0.8982],\n",
       "           ...,\n",
       "           [-0.0873,  0.2374, -0.9659,  ..., -0.2843,  0.2590, -0.9223],\n",
       "           [-0.1230,  0.1661, -0.9775,  ..., -0.2815,  0.2657, -0.9210],\n",
       "           [-0.1273,  0.2128, -0.9677,  ..., -0.2746,  0.2959, -0.9134]],\n",
       "  \n",
       "          [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "           ...,\n",
       "           [-0.1580,  0.1205, -0.9767,  ..., -0.1845,  0.0064, -0.9686],\n",
       "           [-0.1723,  0.0853, -0.9799,  ..., -0.2597, -0.0645, -0.9619],\n",
       "           [-0.1693,  0.1129, -0.9790,  ..., -0.2565, -0.0304, -0.9660]],\n",
       "  \n",
       "          [[ 0.0034,  0.3078, -0.9492,  ..., -0.1923,  0.5105, -0.8358],\n",
       "           [ 0.0044,  0.3168, -0.9461,  ..., -0.2169,  0.5158, -0.8256],\n",
       "           [ 0.0172,  0.3270, -0.9418,  ..., -0.2174,  0.5249, -0.8211],\n",
       "           ...,\n",
       "           [ 0.0069,  0.3704, -0.9267,  ..., -0.1166,  0.4695, -0.8714],\n",
       "           [ 0.0563,  0.3877, -0.9193,  ..., -0.1705,  0.4350, -0.8826],\n",
       "           [ 0.0685,  0.4059, -0.9105,  ..., -0.1672,  0.3944, -0.9029]]]),\n",
       "  'eval_masks': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 1.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 1., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 1., 0.]]])},\n",
       " 'label': tensor([1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "         0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1.]),\n",
       " 'is_train': tensor([1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "batch2 = deepcopy(batch)\n",
    "batch2\n",
    "# model2.forward(batch, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch2['forward']['X'] = batch2['forward'].pop('values')\n",
    "batch2['forward']['missing_mask'] = batch2['forward'].pop('masks')\n",
    "batch2['backward']['X'] = batch2['backward'].pop('values')\n",
    "batch2['backward']['missing_mask'] = batch2['backward'].pop('masks')\n",
    "batch2['label'] = batch2['label'].long()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['deltas', 'evals', 'eval_masks', 'X', 'missing_mask'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch2['forward'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret2 = model2.forward(batch2, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['imputed_data', 'classification_pred', 'consistency_loss', 'reconstruction_loss', 'loss', 'reconstruction', 'classification_loss', 'f_reconstruction', 'b_reconstruction'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss_imp', 'loss_clf', 'loss', 'predictions', 'imputations', 'label', 'is_train', 'evals', 'eval_masks'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0274,  0.2098, -0.9674,  ..., -0.1025,  0.2313, -0.9459],\n",
       "         [ 0.0100,  0.2078, -0.9595,  ..., -0.0484,  0.2020, -0.9595],\n",
       "         [ 0.1600,  0.2573, -0.9499,  ..., -0.3722,  0.4083, -0.8149],\n",
       "         ...,\n",
       "         [ 0.0385, -0.0483, -0.0135,  ...,  0.0392,  0.0822, -0.0963],\n",
       "         [ 0.0418, -0.0525, -0.0162,  ...,  0.0369,  0.0830, -0.0941],\n",
       "         [ 0.0466, -0.0609, -0.0252,  ...,  0.0364,  0.0835, -0.0901]],\n",
       "\n",
       "        [[ 0.0230,  0.2504, -0.9678,  ..., -0.1237, -0.0829, -0.9088],\n",
       "         [ 0.0424,  0.2503, -0.9662,  ..., -0.1164,  0.4028, -0.9069],\n",
       "         [ 0.0594,  0.2558, -0.9629,  ..., -0.1623,  0.3587, -0.9182],\n",
       "         ...,\n",
       "         [ 0.0364, -0.0477, -0.0175,  ...,  0.0417,  0.0839, -0.0963],\n",
       "         [ 0.0401, -0.0520, -0.0206,  ...,  0.0397,  0.0842, -0.0944],\n",
       "         [ 0.0466, -0.0609, -0.0252,  ...,  0.0364,  0.0835,  0.0354]],\n",
       "\n",
       "        [[ 0.0064,  0.2969, -0.9544,  ..., -0.2587,  0.3658, -0.8937],\n",
       "         [-0.0265,  0.2859, -0.9572,  ..., -0.2414,  0.3761, -0.8942],\n",
       "         [-0.0693,  0.3263, -0.9425,  ..., -0.1997,  0.4308, -0.8796],\n",
       "         ...,\n",
       "         [ 0.0417, -0.1215, -0.9590,  ..., -0.3445,  0.5893, -0.7280],\n",
       "         [ 0.1096,  0.3124, -0.9422,  ..., -0.2712,  0.5721, -0.7651],\n",
       "         [-0.0284,  0.2860, -0.9544,  ..., -0.0700,  0.4321, -0.8963]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1273,  0.2128, -0.9677,  ..., -0.2746,  0.2959, -0.9134],\n",
       "         [-0.1230,  0.1661, -0.9775,  ..., -0.2815,  0.2657, -0.9210],\n",
       "         [-0.0873, -0.1081, -0.9659,  ..., -0.2843,  0.2590, -0.9223],\n",
       "         ...,\n",
       "         [-0.1071,  0.1583, -0.9804,  ..., -0.2537,  0.3533, -0.8982],\n",
       "         [-0.1574,  0.1780, -0.9693,  ..., -0.1986,  0.2052, -0.9556],\n",
       "         [-0.1969,  0.1431, -0.9658,  ...,  0.0461,  0.3151, -0.9328]],\n",
       "\n",
       "        [[-0.1693,  0.1129, -0.9790,  ..., -0.2565, -0.0273, -0.9660],\n",
       "         [-0.1723,  0.0853, -0.9799,  ..., -0.2597, -0.0645, -0.9619],\n",
       "         [-0.1580,  0.1205, -0.9767,  ..., -0.1845,  0.0064, -0.9686],\n",
       "         ...,\n",
       "         [ 0.0375, -0.0478, -0.0172,  ...,  0.0419,  0.0847, -0.0974],\n",
       "         [ 0.0401, -0.0520, -0.0206,  ...,  0.0397,  0.0842, -0.0944],\n",
       "         [ 0.0466, -0.0609, -0.0252,  ...,  0.0920,  0.0835, -0.0901]],\n",
       "\n",
       "        [[ 0.0685,  0.4059, -0.9105,  ..., -0.1672,  0.0219, -0.9029],\n",
       "         [ 0.0563,  0.3877, -0.9193,  ..., -0.1705,  0.4350, -0.8826],\n",
       "         [ 0.0069,  0.3704, -0.9267,  ..., -0.1166,  0.4695, -0.8714],\n",
       "         ...,\n",
       "         [ 0.0172,  0.3270, -0.9418,  ..., -0.2174,  0.5249, -0.8211],\n",
       "         [ 0.0044,  0.3168, -0.9461,  ..., -0.2169,  0.5158, -0.8256],\n",
       "         [ 0.0034,  0.3078, -0.9492,  ..., -0.1923,  0.5105, -0.8358]]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret1['imputations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0274,  0.2098, -0.9674,  ..., -0.1025,  0.2313, -0.9459],\n",
       "         [ 0.0100,  0.2078, -0.9595,  ..., -0.0484,  0.2020, -0.9595],\n",
       "         [ 0.1600,  0.2573, -0.9499,  ..., -0.3722,  0.4083, -0.8149],\n",
       "         ...,\n",
       "         [ 0.0395,  0.0706,  0.0614,  ...,  0.0154,  0.0324,  0.1001],\n",
       "         [ 0.0391,  0.0695,  0.0585,  ...,  0.0166,  0.0314,  0.1000],\n",
       "         [ 0.0367,  0.0661,  0.0536,  ...,  0.0194,  0.0320,  0.1018]],\n",
       "\n",
       "        [[ 0.0230,  0.2504, -0.9678,  ..., -0.1237, -0.0259, -0.9088],\n",
       "         [ 0.0424,  0.2503, -0.9662,  ..., -0.1164,  0.4028, -0.9069],\n",
       "         [ 0.0594,  0.2558, -0.9629,  ..., -0.1623,  0.3587, -0.9182],\n",
       "         ...,\n",
       "         [ 0.0383,  0.0702,  0.0632,  ...,  0.0156,  0.0336,  0.1007],\n",
       "         [ 0.0381,  0.0695,  0.0599,  ...,  0.0165,  0.0323,  0.1003],\n",
       "         [ 0.0367,  0.0661,  0.0536,  ...,  0.0194,  0.0320,  0.1624]],\n",
       "\n",
       "        [[ 0.0064,  0.2969, -0.9544,  ..., -0.2587,  0.3658, -0.8937],\n",
       "         [-0.0265,  0.2859, -0.9572,  ..., -0.2414,  0.3761, -0.8942],\n",
       "         [-0.0693,  0.3263, -0.9425,  ..., -0.1997,  0.4308, -0.8796],\n",
       "         ...,\n",
       "         [ 0.0417,  0.0419, -0.9590,  ..., -0.3445,  0.5893, -0.7280],\n",
       "         [ 0.1096,  0.3124, -0.9422,  ..., -0.2712,  0.5721, -0.7651],\n",
       "         [-0.0284,  0.2860, -0.9544,  ..., -0.0700,  0.4321, -0.8963]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1273,  0.2128, -0.9677,  ..., -0.2746,  0.2959, -0.9134],\n",
       "         [-0.1230,  0.1661, -0.9775,  ..., -0.2815,  0.2657, -0.9210],\n",
       "         [-0.0873,  0.0060, -0.9659,  ..., -0.2843,  0.2590, -0.9223],\n",
       "         ...,\n",
       "         [-0.1071,  0.1583, -0.9804,  ..., -0.2537,  0.3533, -0.8982],\n",
       "         [-0.1574,  0.1780, -0.9693,  ..., -0.1986,  0.2052, -0.9556],\n",
       "         [-0.1969,  0.1431, -0.9658,  ...,  0.0461,  0.3151, -0.9328]],\n",
       "\n",
       "        [[-0.1693,  0.1129, -0.9790,  ..., -0.2565,  0.0743, -0.9660],\n",
       "         [-0.1723,  0.0853, -0.9799,  ..., -0.2597, -0.0645, -0.9619],\n",
       "         [-0.1580,  0.1205, -0.9767,  ..., -0.1845,  0.0064, -0.9686],\n",
       "         ...,\n",
       "         [ 0.0385,  0.0697,  0.0638,  ...,  0.0154,  0.0331,  0.1005],\n",
       "         [ 0.0381,  0.0695,  0.0599,  ...,  0.0165,  0.0323,  0.1003],\n",
       "         [ 0.0367,  0.0661,  0.0536,  ..., -0.0058,  0.0320,  0.1018]],\n",
       "\n",
       "        [[ 0.0685,  0.4059, -0.9105,  ..., -0.1672,  0.0156, -0.9029],\n",
       "         [ 0.0563,  0.3877, -0.9193,  ..., -0.1705,  0.4350, -0.8826],\n",
       "         [ 0.0069,  0.3704, -0.9267,  ..., -0.1166,  0.4695, -0.8714],\n",
       "         ...,\n",
       "         [ 0.0172,  0.3270, -0.9418,  ..., -0.2174,  0.5249, -0.8211],\n",
       "         [ 0.0044,  0.3168, -0.9461,  ..., -0.2169,  0.5158, -0.8256],\n",
       "         [ 0.0034,  0.3078, -0.9492,  ..., -0.1923,  0.5105, -0.8358]]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret2['imputed_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model_brits_att(\n",
       "  (rits_f): Model_rits_att(\n",
       "    (rnn_cell): LSTMCell(24, 32)\n",
       "    (temp_decay_h): TemporalDecay()\n",
       "    (temp_decay_x): TemporalDecay()\n",
       "    (hist_reg): Linear(in_features=32, out_features=12, bias=True)\n",
       "    (feat_reg): FeatureRegression()\n",
       "    (weight_combine): Linear(in_features=24, out_features=12, bias=True)\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "    (out): Linear(in_features=960, out_features=1, bias=True)\n",
       "    (W_s1): Linear(in_features=32, out_features=350, bias=True)\n",
       "    (W_s2): Linear(in_features=350, out_features=30, bias=True)\n",
       "  )\n",
       "  (rits_b): Model_rits_att(\n",
       "    (rnn_cell): LSTMCell(24, 32)\n",
       "    (temp_decay_h): TemporalDecay()\n",
       "    (temp_decay_x): TemporalDecay()\n",
       "    (hist_reg): Linear(in_features=32, out_features=12, bias=True)\n",
       "    (feat_reg): FeatureRegression()\n",
       "    (weight_combine): Linear(in_features=24, out_features=12, bias=True)\n",
       "    (dropout): Dropout(p=0.25, inplace=False)\n",
       "    (out): Linear(in_features=960, out_features=1, bias=True)\n",
       "    (W_s1): Linear(in_features=32, out_features=350, bias=True)\n",
       "    (W_s2): Linear(in_features=350, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRITSLightningModule(\n",
       "  (model): MultiTaskBRITS(\n",
       "    (model): MyBackboneBRITS(\n",
       "      (rits_f): MyBackboneRITS(\n",
       "        (rnn_cell): LSTMCell(24, 32)\n",
       "        (temp_decay_h): TemporalDecay()\n",
       "        (temp_decay_x): TemporalDecay()\n",
       "        (hist_reg): Linear(in_features=32, out_features=12, bias=True)\n",
       "        (feat_reg): FeatureRegression()\n",
       "        (combining_weight): Linear(in_features=24, out_features=12, bias=True)\n",
       "      )\n",
       "      (rits_b): MyBackboneRITS(\n",
       "        (rnn_cell): LSTMCell(24, 32)\n",
       "        (temp_decay_h): TemporalDecay()\n",
       "        (temp_decay_x): TemporalDecay()\n",
       "        (hist_reg): Linear(in_features=32, out_features=12, bias=True)\n",
       "        (feat_reg): FeatureRegression()\n",
       "        (combining_weight): Linear(in_features=24, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (f_classifier): None\n",
       "    (b_classifier): None\n",
       "    (out): Linear(in_features=960, out_features=2, bias=True)\n",
       "    (W_s1): Linear(in_features=32, out_features=30, bias=True)\n",
       "    (W_s2): Linear(in_features=30, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
